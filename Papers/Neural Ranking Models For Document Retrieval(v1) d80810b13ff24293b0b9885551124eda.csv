Name,Year,Paper title,Total Parameters in Model,Data sets,Implementation,Results table,Benchmark dataset(Common applied benchmark),Benchmark leaderboard,Illustration of the model,Note
DSSM,2013,"Learning Deep Structured Semantic Models
for Web Search using Clickthrough Data",30K(fixed wordhashing(n_gram countvectorizer))*300+300(mlp_hidde)*300(mlp_hidde)+300*128(output)=9.13M(omitted bias in dense layers)  190082⇒0.19M(wiki_qa in https://github.com/NTMC-Community/MatchZoo),A real-world click-through data set (unpublished),"https://github.com/PaddlePaddle/PaddleRec/tree/release/2.1.0/models/match/dssm, https://github.com/NTMC-Community/MatchZoo",https://www.notion.so/bbd5588859284f2c946e2c1c57b16ba9,NAN,,https://kishorepv.github.io/images/DSSM_layers.png,1. Only took the L-WH DNN setting with 500K vocab word hashing 30K
ARC-I,2014,Convolutional Neural Network Architectures for Matching Natural Language Sentences,3088781⇒3M(wiki_qa in https://github.com/NTMC-Community/MatchZoo) embedding: 30059*100,"Word2Vec embedding on : Wikipedia (∼1Bwords),Weibo data (∼300M words)  1.Sentence Completion from https://www.jmlr.org/papers/volume5/lewis04a/lewis04a.pdf 2. Matching A Response to A Tweet https://aclanthology.org/D13-1096/  3. Paraphrase Identification http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.585.5488&rep=rep1&type=pdf",https://github.com/NTMC-Community/MatchZoo-py,"https://www.notion.so/abf61e89a7f345e9901f2577dd851424, https://www.notion.so/dc0c2c6122e04dc38c15d1e2ea87c7e7, https://www.notion.so/c81df7f759d742d69d4f5f66cf8b57ef",,,https://www.notion.so/4dfbb7ae03b543dd9eea1f8f49f7e10b,1.Representation based
ARC-II,2014,Convolutional Neural Network Architectures for Matching Natural Language Sentences,3036029⇒3M(wiki_qa in https://github.com/NTMC-Community/MatchZoo) embedding: 30059*100,"Word2Vec embedding on : Wikipedia (∼1Bwords),Weibo data (∼300M words)  1.Sentence Completion from https://www.jmlr.org/papers/volume5/lewis04a/lewis04a.pdf 2. Matching A Response to A Tweet https://aclanthology.org/D13-1096/  3. Paraphrase Identification http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.585.5488&rep=rep1&type=pdf",https://github.com/NTMC-Community/MatchZoo-py,"https://www.notion.so/6fecedd74fbb401bb721f27096bcfa5a, https://www.notion.so/f7c599aa91294a598310933c380c575a, https://www.notion.so/1948d02e079840b583c39bec2e6cd53a",,https://paperswithcode.com/sota/question-answering-on-semevalcqa,https://www.notion.so/3aa71d65b958444eb0f956618ed0e016,1.Introduce interatcion at the beginning
DRMM,2016,"A Deep Relevance Matching Model for Ad-hoc Retrieval ","query_term_length(vocab_size)*histgram_size(input_layer) + n_DenseLayer+ DenseLayer(1) with embedding:3006163⇒3M(wiki_qa in https://github.com/NTMC-Community/MatchZoo)  without embedding: 127423⇒0.12M(wiki_qa in https://github.com/NTMC-Community/MatchZoo) ",Robust04 and ClueWeb-09-Cat-B,https://github.com/sebastian-hofstaetter/neural-ranking-drmm,"https://www.notion.so/ead239d9b2b94a9e87da19f84667d65b, https://www.notion.so/fb25d4e761e74cfbb7b4734ed7417850",http://www.bigdatalab.ac.cn/benchmark/bm/dd?data=Robust04-Title     https://lemurproject.org/clueweb09/https://lemurproject.org/clueweb09/,https://paperswithcode.com/sota/ad-hoc-information-retrieval-on-trec-robust04,https://www.notion.so/9c04bf25a04b4fab8931c87b7c4b26fc,
MatchPyramid,2016b,"1.Text matching as image recognition 2. A Study of MatchPyramid Models on Ad-hoc Retrieval  ","with embedding:3011661⇒3M without embedding: 5761 (wiki_qa in https://github.com/NTMC-Community/MatchZoo) ",Robust04,https://github.com/NTMC-Community/MatchZoo-py,https://www.notion.so/208cd9879be04c21a71b264fe32cc372,"http://www.bigdatalab.ac.cn/benchmark/bm/dd?data=Robust04-Title   ",,"https://www.notion.so/06b913a6756b459b8c74c00b19fdd12d, https://www.notion.so/fadaa867d4b94fe6934833494e620751",
DeepRank,2017,DeepRank: A New Deep Architecture for Relevance Ranking in Information Retrieval,with embedding:9862169⇒9.86M embedding size:193368*50⇒9.66M(https://github.com/pl8787/DeepRank_PyTorch),LETOR4.0 benchmark(merged MQ2007 and MQ2008) and  a large scale click- through data(ChineseClick(seems unpublished)),https://github.com/pl8787/DeepRank_PyTorch,"https://www.notion.so/fd194382d8d64e90aedbb2839f11e24b, https://www.notion.so/06be3051ec3f40f88b266c0196a76e1d, https://www.notion.so/ee704bf9495d43939336ea1445e3223c",https://www.microsoft.com/en-us/research/project/letor-learning-rank-information-retrieval/#!letor-4-0,,"https://www.notion.so/ebf5af1497e84580a29b609111cd7f73, https://www.notion.so/a9aaf608eabf446aa3b2af3b44152c99",1.MQ2008 is merged with MQ2007 kept the same name 2. Models parameter numbers are configured to fit the size of the dataset[p6] 3.Only took the performance of DeepRank-CNN on MQ2008
DEUT,2017,"Learning to Match Using Local and Distributed Representations of Text for Web Search
","5.4M(hand cauculated from original paper)  5415904⇒5.4M(https://github.com/NTMC-Community/MatchZoo) ",Sampled from Bing’s search logs(unpublished),"https://github.com/bmitra-msft/NDRM/blob/master/notebooks/Duet.ipynb, https://github.com/NTMC-Community/MatchZoo-py","https://www.notion.so/00dc19f008c24b8e8f8b8710e14168ad, https://www.notion.so/4661a8b9b44d450f8e8c43a6135b4fab",NAN,,"https://www.notion.so/0a5c569c78f342df83bb5c387de7bf99, https://www.notion.so/c0d7b3ff9e2245a2b7d766c4ee9c6d2a","
"
PACRR,2017,PACRR: A Position-Aware Neural IR Model for Relevance Matching,"11329(similarity matrices(1.Link from implementation not working,2.Generated from a pre-trained word2vec) given as input) ","CLUEWEB09, CLUEWEB12 ,TREC Web Track 2012–14",https://github.com/khui/copacrr,"https://www.notion.so/21ebbd0157334cc2a8a979ef1dd10885, https://www.notion.so/131483349817435cbff9183e35834fdd",https://trec.nist.gov/data/web2012.html,,https://www.notion.so/a943c60fc8d541939a9bc06205378818,
KNRM,2017b,End-to-End Neural Ad-hoc Ranking with Kernel Pooling,3005912 ⇒3M(wiki_qa in https://github.com/NTMC-Community/MatchZoo),Sampled from search logs of Sogou(unpulished),"https://github.com/AdeDZY/K-NRM, https://github.com/NTMC-Community/MatchZoo/blob/master/matchzoo/models/knrm.py, https://github.com/NTMC-Community/MatchZoo-py/tree/master/matchzoo/models","https://www.notion.so/3f406f3e88d045a8877aef332b895ab2, https://www.notion.so/5ad6c1996c054e6a8a8244d8a70a6bef",NAN,,https://www.notion.so/d4d4606a1535429d9321eabf2ba8662f,
ColBert,2020,ColBERT: Efficient and Effective Passage Search via Contextualized Late Interaction over BERT,"https://colab.research.google.com/drive/1i4NmjOOoIyIax7m_jkcXqX_WdgG-71jl?usp=sharing=66.9M(DistilBert-based ColBERT)  110,005,257=110M(https://github.com/Moradnejad/ColBERT-Using-BERT-Sentence-Embedding-for-Humor-Detection/blob/master/colbert-using-pretrained-model.ipynb)",MS MARCO and TREC-CAR,"https://github.com/Moradnejad/ColBERT-Using-BERT-Sentence-Embedding-for-Humor-Detection, https://huggingface.co/sebastian-hofstaetter/colbert-distilbert-margin_mse-T2-msmarco","https://www.notion.so/2e3087647fd24a7aa42d2c489e61469e, https://www.notion.so/089490eaf71943368c2d3cfad168acd7",https://microsoft.github.io/msmarco/https://trec-car.cs.unh.edu/,https://paperswithcode.com/sota/humor-detection-on-200k-short-texts-for-humor-1  https://microsoft.github.io/msmarco/https://microsoft.github.io/msmarco/,https://www.notion.so/787f8f4c836546bf96f9d98930882765,1.DistilBert-based ColBERT implementation outperforms the original model in paper on MSMARCO
BERT,2020,Passage Re-ranking with BERT,109482240⇒109M(Finetuned Bert-Base),MS MARCO and TREC-CAR,https://github.com/nyu-dl/dl4marco-bert,https://www.notion.so/cc3a362e125748c5a12a4272c2b99e04,https://microsoft.github.io/msmarco/https://trec-car.cs.unh.edu/,https://microsoft.github.io/msmarco/https://microsoft.github.io/msmarco/,,
MarkedBERT,2020,MarkedBERT: Integrating Traditional IR Cues in Pre-trained Language Models for Passage Retrieval,109482240⇒109M(Finetuned Bert-Base),"MS MARCO ",https://github.com/BOUALILILila/markers_bert,https://www.notion.so/4dca0af6d3724a778e000ccfad25b138,https://microsoft.github.io/msmarco/,https://microsoft.github.io/msmarco/https://microsoft.github.io/msmarco/,https://www.notion.so/bcfc19df9cc3412183463860682e773c,
TK(Transformer Kernel),2020,https://www.semanticscholar.org/paper/Interpretable-%26-Time-Budget-Constrained-for-Hofst%C3%A4tter-Zlabinger/6dbdc34000b034b75b8ff70872fc7c35549e273a,,MS MARCO and TREC-CAR,https://github.com/sebastian-hofstaetter/matchmaker,,,,,
Doc2Query,2019,https://arxiv.org/abs/1904.08375.pdf,,MS MARCO and TREC-CAR,https://github.com/nyu-dl/dl4ir-doc2query,https://www.notion.so/a4977b03c19c439f8a47dac6e21d7f09,https://microsoft.github.io/msmarco/https://trec-car.cs.unh.edu/,https://microsoft.github.io/msmarco/https://microsoft.github.io/msmarco/,https://www.notion.so/edf6039bd14743719b92b1c6db9e7175,"The idea behind doc2query, a form of document expansion, is to train a model, that when given
an input document, generates questions that the document might answer. These predicted questions
are then appended to the original documents, which are then indexed as before."
DocTTTTTQuery/T5,2019,https://cs.uwaterloo.ca/~jimmylin/publications/Nogueira_Lin_2019_docTTTTTquery-v2.pdf,,"MS MARCO ",https://github.com/castorini/docTTTTTquery,,https://microsoft.github.io/msmarco/,https://microsoft.github.io/msmarco/https://microsoft.github.io/msmarco/,,"docTTTTTquery is much more effective than doc2query and (almost) as effective as the best non-BERT ranking model, while increasing query latency (time to retrieve 1000 docs per query) only slightly compared to vanilla BM25"
UED,,,,,,,,,,
DeepCT,2019b,https://arxiv.org/abs/1910.10687,,MS MARCO and TREC-CAR,https://github.com/AdeDZY/DeepCT,"https://www.notion.so/98909d9feaca47da842f648de46d6445, https://www.notion.so/86300495bc3a4b83a324349b80bb9cf5, https://www.notion.so/7af47c7f6bf740b5a0f2ba04d1e3b083, https://www.notion.so/0b89d0162d9148c9ba9a001316543093, https://www.notion.so/54d4b2b87708462bbb772b9aa353b971",https://microsoft.github.io/msmarco/https://trec-car.cs.unh.edu/,https://microsoft.github.io/msmarco/https://microsoft.github.io/msmarco/,,"Term Reweighting method;Proposed a method to weight terms by their roles in a specific
text context"
HDCT,2020,http://www.cs.cmu.edu/~zhuyund/papers/TheWebConf_2020_Dai.pdf,,"ClueWeb09-C;ClueWeb12-C;MS MARCO ",https://github.com/AdeDZY/DeepCT,"https://www.notion.so/d881b8fa3dd94fdeaa3f4948d673afd4, https://www.notion.so/0e38e399f31d45eb8bed2b34ffca2e8f, https://www.notion.so/29387abd99b84e8fa19cb7ac918ace40",https://microsoft.github.io/msmarco/,https://microsoft.github.io/msmarco/https://microsoft.github.io/msmarco/,https://www.notion.so/f63de6b1507e4a2da90ceb9e41440cbd,Extends DeepCT to support long documents and weakly supervised training. This paper also proposes two approaches that enable training HDCT without relevance labels. Experiments show that an index using HDCT weights significantly improved the retrieval accuracy compared to typical term-frequency and state-of-the-art embedding-based indexes
ANCE,2020b,https://arxiv.org/abs/2007.00808.pdf,,TREC DL; MS MARCO,https://github.com/microsoft/ANCE,"https://www.notion.so/b080dd07930c464b8e3b01401f7ff768, https://www.notion.so/e63be22570ce48ea853e6e1d6afb2536",TREC DL; MS MARCO,https://microsoft.github.io/msmarco/https://microsoft.github.io/msmarco/;,,"This paper presents Approximate nearest neighbor Negative Contrastive Estimation (ANCE), a training mechanism that constructs negatives from an Approximate Nearest Neighbor (ANN) index of the corpus, which is parallelly updated with the learning process to select more realistic negative training instances. This fundamentally resolves the discrepancy between the data distribution used in the training and testing of DR. In the experiments, ANCE boosts the BERT-Siamese DR model to outperform all competitive dense and sparse retrieval baselines. It nearly matches the accuracy of sparse-retrieval-and-BERT-reranking using dot-product in the ANCE-learned representation space and provides almost 100x speed-up."
PROP,2020,https://arxiv.org/abs/2010.10137,,Pre-training Corpus: MS MARCO ;English Wikipedia Downstream Dataset: Robust04;ClueWeb09-B;Gov2;Million Query Track 2007 (MQ2007);Million Query Track 2008 (MQ2008),https://github.com/Albert-Ma/PROP,"https://www.notion.so/3cffef4daca548c7b5cdd266471fa3eb, https://www.notion.so/3e312b86e6734c03b51edeeea5617ecc, https://www.notion.so/5a731dcc95894c72b6dc36c1fc0928e7",http://www.bigdatalab.ac.cn/benchmark/bm/dd?data=Robust04-Title  https://lemurproject.org/clueweb09/https://lemurproject.org/clueweb09/ https://microsoft.github.io/msmarco/,https://microsoft.github.io/msmarco/https://microsoft.github.io/msmarco/,,"PROP is inspired by the classical statistical language model for IR, specifically the query likelihood model, which assumes that the query is generated as the piece of text representative of the “ideal” document. Based on this idea,  the authors construct the representative words prediction (ROP) task for pre-training"
COIL,,,,,,,,,,
monoBERT+duoBERT,2019,https://arxiv.org/abs/1910.14424,,Target Corpus Pre-training (TCP)  ;MS MARCO; TREC CAR,"https://github.com/castorini/duobert, https://github.com/nyu-dl/dl4marco-bert",https://www.notion.so/8c1c5772556a4c56973f1f1a2e18475d,https://microsoft.github.io/msmarco/https://trec-car.cs.unh.edu/,https://microsoft.github.io/msmarco/https://microsoft.github.io/msmarco/,https://www.notion.so/36869b52a9154037a54aeb41755b8dfa,
SEED-Encoder,2021b,https://arxiv.org/abs/2102.09206,,,,,,,,